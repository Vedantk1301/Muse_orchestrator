LOGIC from very earlier version for diverse queries

Intent classification (fashion-only, no budget terms inside queries) # ============================================================================= async def t_classify_intent( query: str, user_gender: Optional[str] = None, forced_type: Optional[str] = None, ) -> Dict[str, Any]: """ Classify the fashion search intent. Uses FAST_MODEL (Responses API) and caches results. Uses plain JSON output for robustness. - Always uses gender neutral language in queries. - For discovery or pairing, always returns 3 short SKU like queries. - Queries MUST be fashion / catalog friendly only (no 'under 5000', no generic chit chat). """ # Ignore gender for now, we want fully neutral behaviour user_gender = None cache_key = _cache_key("intent", query.lower(), forced_type or "") cached = await INTENT_CACHE.get(cache_key) if cached: logger.debug("üíæ intent cache HIT") return cached t0 = time.perf_counter() logger.info("üß† classify_intent", query=query[:80], forced_type=forced_type) system_prompt = """ You are an intent classifier for a fashion search bot. You must return ONLY a JSON object with this exact schema (no extra text, no explanations): { "search_type": "specific" | "discovery" | "pairing", "queries": ["string", "string", ...] } Rules for ALL queries: - They must be SIMPLE, DIRECT fashion product search strings. - Examples: "Cotton Linen Shorts", "Navy Blue Trousers", "Beige Oversized T Shirt", "Floral Midi Dress". - Only talk about clothing, footwear, and accessories. - All queries must be gender neutral. Do NOT use words like "men", "women", "male", "female". - You MAY use "unisex" if you want a neutral signal. - Do NOT include any price or budget words in queries. - Do NOT include generic prompts like "what is trending" or "good outfits". - Do NOT include non fashion topics like weather, politics, coding, AI, etc. FORBIDDEN WORDS (Do NOT use these unless explicitly part of the product name): - "India" - "Trend", "Trending", "Viral" - "Winterwear", "Summerwear" - "Best", "Top", "Cheap", "Online" Types: - "specific": - User is clearly looking for ONE focused thing. - Return exactly 1 tight query in queries. - "discovery": - User is browsing, says things like "ideas", "options", "trending", "what's in", "show me some". - Return exactly 3 short, concrete queries that each describe one product family. - Make them diverse but simple. - "pairing": - User wants items that go with another item. - Return exactly 3 short, complementary queries. Remember: - queries MUST be short and simple, not long paragraphs. - NO "India" suffix. - NO "Trending" prefix. """.strip() try: response = await asyncio.to_thread( client.responses.create, model=Config.FAST_MODEL, input=[ {"role": "system", "content": system_prompt}, { "role": "user", "content": json.dumps({"query": query}), }, ], max_output_tokens=200, ) raw_text = (response.output_text or "").strip() parsed: Optional[Dict[str, Any]] = None if raw_text: try: parsed = json.loads(raw_text) except Exception as e: logger.error( "‚ùå classify_intent JSON parse failed", raw=raw_text, error=str(e), ) if not parsed: # Safe default result = {"search_type": "specific", "queries": [query]} await INTENT_CACHE.set(cache_key, result) return result search_type = parsed.get("search_type", "specific") if forced_type in ("specific", "discovery", "pairing"): search_type = forced_type queries = parsed.get("queries", [query]) # Normalize queries and enforce counts if search_type == "specific": queries = queries[:1] else: # Discovery or pairing: enforce 3 queries if len(queries) < 3: base = query expanded = [] for q in queries: if q and q not in expanded: expanded.append(q) while len(expanded) < 3: expanded.append(base) queries = expanded[:3] else: queries = queries[:3] result = {"search_type": search_type, "queries": queries} await INTENT_CACHE.set(cache_key, result) ms = int((time.perf_counter() - t0) * 1000) logger.success( "‚úÖ classify_intent", duration_ms=ms, search_type=search_type, num_queries=len(queries), parsed=result, ) return result except Exception as e: ms = int((time.perf_counter() - t0) * 1000) logger.error("‚ùå classify_intent failed", duration_ms=ms, error=str(e)) # Safe default result = {"search_type": "specific", "queries": [query]} await INTENT_CACHE.set(cache_key, result) return result # ============================================================================= # Product search (Qdrant) ‚Äì multi-query, parallel, fashion-only # ============================================================================= async def t_search_fashion_products( query: str, user_gender: Optional[str] = None, search_type: str = "auto" ) -> Dict[str, Any]: """ Product search tool (card-friendly). Returns: { "products": [...], "total_found": int, "search_type": "specific" | "discovery" | "pairing", "queries_used": [...], "best_score": float } Behaviour: - Always treats searches as gender neutral internally. - For discovery / pairing: expands to 3 short fashion-only queries and runs them in PARALLEL. - Combines products from all queries, dedupes by product id, then reranks (if needed). """ # We always treat searches as gender neutral internally user_gender = None cache_key = _cache_key("search", query.lower(), search_type) cached = await SEARCH_CACHE.get(cache_key) if cached: logger.success("üíæ search cache HIT") return cached t0 = time.perf_counter() logger.info("üîç search_fashion_products", query=query, search_type=search_type) try: await Services.ensure_loaded() # Decide when to call classifier: # - auto / discovery / pairing => classifier with optional forced type # - specific => just one query ql = query.lower() if search_type in ("auto", "discovery", "pairing"): forced_type = None if search_type == "auto" else search_type intent = await t_classify_intent(query, user_gender, forced_type=forced_type) search_type = intent["search_type"] queries = intent["queries"] else: search_type = "specific" queries = [query] # Extra specialisation for "trending" like queries if "trend" in ql or "trending" in ql: search_type = "discovery" # Rely on classifier for queries, do not hardcode "India" ones here. logger.debug("üìã Search queries", type=search_type, queries=queries) # Embedding embed_t0 = time.perf_counter() vectors = await Services.embed(queries) embed_ms = int((time.perf_counter() - embed_t0) * 1000) logger.perf("embed", embed_ms, num_queries=len(queries)) # Qdrant search from qdrant_client.http import models as rest async def _search_one(q: str, vec: List[float]): def _do(): return Services.qdr.query_points( collection_name=Config.CATALOG_COLLECTION, query=vec, limit=( Config.PRODUCTS_PER_QUERY if len(queries) > 1 else Config.SIMPLE_SEARCH_LIMIT ), with_payload=True, search_params=rest.SearchParams(hnsw_ef=Config.HNSW_EF), ) return await asyncio.to_thread(_do) search_t0 = time.perf_counter() results = await asyncio.gather( *[_search_one(q, v) for q, v in zip(queries, vectors)], return_exceptions=True, ) search_ms = int((time.perf_counter() - search_t0) * 1000) logger.perf("qdrant_search", search_ms, num_queries=len(queries)) # Aggregate products ‚Üí CARD FORMAT # Interleave results from multiple queries to ensure diversity # e.g. [Q1_1, Q2_1, Q3_1, Q1_2, Q2_2, Q3_2, ...] results_lists = [] best_score = 0.0 per_query = ( min(Config.FINAL_RERANK_TOP_K * 2, Config.PRODUCTS_PER_QUERY) if len(queries) > 1 else Config.SIMPLE_SEARCH_LIMIT ) for i, (q, result) in enumerate(zip(queries, results)): if isinstance(result, Exception): logger.warning(f"Query {i} failed", error=str(result)) continue q_products = [] for point in (result.points or [])[:per_query]: payload = point.payload or {} commerce = payload.get("commerce") or {} pid = ( payload.get("product_id") or payload.get("id") or getattr(point, "id", None) ) if not pid: continue score = float(point.score) best_score = max(best_score, score) card = { "id": pid, "product_id": pid, "title": payload.get("title"), "brand": payload.get("brand"), "category": payload.get("category_leaf"), "image_url": payload.get("primary_image") or payload.get("image_url"), "url": payload.get("url"), "price": commerce.get("price"), "price_inr": commerce.get("price_inr"), "score": score, "from_query": q, } q_products.append(card) results_lists.append(q_products) # Interleave all_products: List[Dict[str, Any]] = [] seen_ids = set() if not results_lists: pass else: max_len = max(len(lst) for lst in results_lists) for i in range(max_len): for lst in results_lists: if i < len(lst): p = lst[i] if p["id"] not in seen_ids: seen_ids.add(p["id"]) all_products.append(p) # Only sort by score if we have a SINGLE query. # If multiple, we trust the interleaving to provide better relevance/diversity mix. if len(queries) == 1: all_products.sort(key=lambda x: x["score"], reverse=True) logger.debug( "üì¶ Aggregated products", count=len(all_products), best_score=best_score ) # Optional rerank if all_products and best_score < Config.TAU_NO_RERANK: rerank_t0 = time.perf_counter() try: texts = [ f"{p.get('title') or ''} {p.get('brand') or ''} {p.get('category') or ''}" for p in all_products ] indices = await Services.rerank( query, texts, top_k=min(Config.FINAL_RERANK_TOP_K, len(texts)), ) all_products = [ all_products[i] for i in indices if i < len(all_products) ] rerank_ms = int((time.perf_counter() - rerank_t0) * 1000) logger.perf("rerank", rerank_ms, num_products=len(all_products)) except Exception as e: logger.warning("Rerank failed", error=str(e)) all_products = all_products[: Config.FINAL_RERANK_TOP_K] else: all_products = all_products[: Config.FINAL_RERANK_TOP_K] logger.debug( "‚ö° Skipped rerank", reason="high_confidence" if best_score >= Config.TAU_NO_RERANK else "no_products", ) result_payload = { "products": all_products, "total_found": len(all_products), "search_type": search_type, "queries_used": queries, "best_score": best_score, } await SEARCH_CACHE.set(cache_key, result_payload) total_ms = int((time.perf_counter() - t0) * 1000) logger.success( "‚úÖ search completed", duration_ms=total_ms, products=len(all_products), score=best_score, ) return result_payload except Exception as e: ms = int((time.perf_counter() - t0) * 1000) logger.error("‚ùå search failed", duration_ms=ms, error=str(e)) logger.error(traceback.format_exc()) return { "products": [], "total_found": 0, "search_type": search_type, "queries_used": [query], "best_score": 0.0, "error": str(e), }